{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 朱晉輝 Chin-Hui Chu\n",
    "\n",
    "Student ID: r12944041\n",
    "\n",
    "GitHub ID: CHINHUICHU\n",
    "\n",
    "Kaggle name: Chin Hui Chu\n",
    "\n",
    "Kaggle private scoreboard snapshot:![kaggle](kaggle_ranking.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the emotion classification project\"\"\"\n",
    "    MODEL_NAME = \"roberta-base\"\n",
    "    NUM_LABELS = 8\n",
    "    MAX_LENGTH = 128\n",
    "    BATCH_SIZE = 256\n",
    "    NUM_EPOCHS = 1\n",
    "    LEARNING_RATE = 2e-5\n",
    "    SEED = 42\n",
    "    OUTPUT_DIR = \"/content/drive/MyDrive/dm-2024/roberta_emotion_results\"\n",
    "\n",
    "    EMOTION_MAPPING = {\n",
    "        'anger': 0,\n",
    "        'anticipation': 1,\n",
    "        'disgust': 2,\n",
    "        'fear': 3,\n",
    "        'sadness': 4,\n",
    "        'surprise': 5,\n",
    "        'trust': 6,\n",
    "        'joy': 7\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import emoji\n",
    "from typing import Tuple\n",
    "from datasets import Dataset\n",
    "\n",
    "class DataProcessor:\n",
    "    @staticmethod\n",
    "    def read_csv_file(file_path: str, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"Read and load CSV file\"\"\"\n",
    "        try:\n",
    "            return pd.read_csv(file_path, **kwargs)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File '{file_path}' not found\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def read_json_file(file_path: str) -> list:\n",
    "        \"\"\"Read and process JSON file\"\"\"\n",
    "        try:\n",
    "            data = []\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    if line.strip():\n",
    "                        try:\n",
    "                            tweet_data = json.loads(line.strip())\n",
    "                            processed_tweet = {\n",
    "                                'score': tweet_data.get('_score'),\n",
    "                                'index': tweet_data.get('_index'),\n",
    "                                'crawl_date': tweet_data.get('_crawldate'),\n",
    "                                'type': tweet_data.get('_type'),\n",
    "                                'tweet_id': tweet_data.get('_source', {}).get('tweet', {}).get('tweet_id'),\n",
    "                                'text': tweet_data.get('_source', {}).get('tweet', {}).get('text'),\n",
    "                                'hashtags': tweet_data.get('_source', {}).get('tweet', {}).get('hashtags', [])\n",
    "                            }\n",
    "                            data.append(processed_tweet)\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            print(f\"Error parsing JSON object: {str(e)}\")\n",
    "                            continue\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading JSON file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Clean and process text data\"\"\"\n",
    "        try:\n",
    "            decoded_text = text.encode().decode('unicode-escape')\n",
    "            decoded_text = emoji.demojize(decoded_text)\n",
    "        except (UnicodeError, AttributeError):\n",
    "            decoded_text = text\n",
    "\n",
    "        decoded_text = re.sub(r'\\\\u[0-9a-fA-F]{4}', '', decoded_text)\n",
    "        return decoded_text.strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_text_hashtags(row) -> str:\n",
    "        \"\"\"Merge text and hashtags\"\"\"\n",
    "        text = row['text'] if isinstance(row['text'], str) else ''\n",
    "        hashtags = row['hashtags'] if isinstance(row['hashtags'], list) else []\n",
    "\n",
    "        cleaned_text = DataProcessor.clean_text(text)\n",
    "\n",
    "        for hashtag in hashtags:\n",
    "            hashtag_text = f\"#{hashtag}\"\n",
    "            if hashtag_text not in cleaned_text:\n",
    "                cleaned_text += f\" {hashtag_text}\"\n",
    "\n",
    "        return cleaned_text.strip()\n",
    "\n",
    "    @classmethod\n",
    "    def prepare_dataset(cls, df: pd.DataFrame, is_training: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Prepare dataset for training or testing\"\"\"\n",
    "        processed_df = df.copy()\n",
    "        processed_df['text'] = processed_df.apply(cls.merge_text_hashtags, axis=1)\n",
    "\n",
    "        if is_training:\n",
    "            return processed_df[['tweet_id', 'text', 'emotion']]\n",
    "        return processed_df[['tweet_id', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ModelUtils:\n",
    "    @staticmethod\n",
    "    def calculate_metrics(predictions, labels):\n",
    "        \"\"\"Calculate model metrics\"\"\"\n",
    "        f1_per_class = f1_score(labels, predictions, average=None)\n",
    "        mean_f1 = f1_score(labels, predictions, average='macro')\n",
    "        return {\n",
    "            'mean_f1': mean_f1,\n",
    "            'f1_per_class': f1_per_class\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_metrics(train_losses, mean_f1_scores, output_dir):\n",
    "        \"\"\"Plot training metrics\"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.title('Training Loss over Steps')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(mean_f1_scores, label='Mean F1 Score')\n",
    "        plt.title('Mean F1 Score over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'training_metrics.png'))\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_data_for_model(train_df, test_df, tokenizer, max_length=128):\n",
    "        \"\"\"Prepare data for model training\"\"\"\n",
    "        train_dict = {\n",
    "            'text': train_df['text'].tolist(),\n",
    "            'labels': train_df['emotion'].map(Config.EMOTION_MAPPING).tolist(),\n",
    "            'tweet_id': train_df['tweet_id'].tolist()\n",
    "        }\n",
    "\n",
    "        test_dict = {\n",
    "            'text': test_df['text'].tolist(),\n",
    "            'tweet_id': test_df['tweet_id'].tolist()\n",
    "        }\n",
    "        if 'emotion' in test_df.columns:\n",
    "            test_dict['labels'] = test_df['emotion'].map(Config.EMOTION_MAPPING).tolist()\n",
    "\n",
    "        train_dataset = Dataset.from_dict(train_dict)\n",
    "        test_dataset = Dataset.from_dict(test_dict)\n",
    "\n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(\n",
    "                examples['text'],\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=max_length\n",
    "            )\n",
    "\n",
    "        train_remove_cols = ['text', 'tweet_id']\n",
    "        test_remove_cols = ['text', 'tweet_id'] if 'emotion' not in test_df.columns else ['text', 'tweet_id']\n",
    "\n",
    "        train_dataset = train_dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=train_remove_cols,\n",
    "            desc=\"Tokenizing train dataset\"\n",
    "        )\n",
    "\n",
    "        test_dataset = test_dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=test_remove_cols,\n",
    "            desc=\"Tokenizing test dataset\"\n",
    "        )\n",
    "\n",
    "        return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    get_scheduler\n",
    ")\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# trainer.py\n",
    "class EmotionClassificationTrainer:\n",
    "    def __init__(self, config, accelerator):\n",
    "        self.config = config\n",
    "        self.accelerator = accelerator\n",
    "        self.logger = get_logger(__name__)\n",
    "        self.setup_model_and_tokenizer()\n",
    "\n",
    "    def setup_model_and_tokenizer(self):\n",
    "        self.config_model = AutoConfig.from_pretrained(\n",
    "            self.config.MODEL_NAME,\n",
    "            num_labels=self.config.NUM_LABELS,\n",
    "            finetuning_task=\"emotion_classification\"\n",
    "        )\n",
    "\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(self.config.MODEL_NAME)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.config_model.pad_token_id = self.tokenizer.pad_token_id\n",
    "\n",
    "        self.model = RobertaForSequenceClassification.from_pretrained(\n",
    "            self.config.MODEL_NAME,\n",
    "            config=self.config_model,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "    def _setup_optimizer_and_scheduler(self, num_training_steps):\n",
    "        \"\"\"Setup optimizer and learning rate scheduler\"\"\"\n",
    "        # Optimizer with weight decay\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters()\n",
    "                          if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.01,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters()\n",
    "                          if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters,\n",
    "                                    lr=self.config.LEARNING_RATE)\n",
    "\n",
    "        # Learning rate scheduler\n",
    "        scheduler = get_scheduler(\n",
    "            name=\"linear\",\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=num_training_steps,\n",
    "        )\n",
    "\n",
    "        return optimizer, scheduler\n",
    "\n",
    "    def _make_predictions(self, eval_dataloader):\n",
    "        \"\"\"Make predictions on the evaluation dataset\"\"\"\n",
    "        self.model.eval()\n",
    "        all_predictions = []\n",
    "        all_probs = []\n",
    "\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Making predictions\"):\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch)\n",
    "\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "            predictions, probabilities = self.accelerator.gather(\n",
    "                (predictions, probabilities))\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probs.extend(probabilities.cpu().numpy())\n",
    "\n",
    "        return all_predictions, all_probs\n",
    "\n",
    "    def _save_checkpoint(self, epoch):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        if self.accelerator.is_main_process:\n",
    "            checkpoint_dir = os.path.join(self.config.OUTPUT_DIR, f\"checkpoint-{epoch}-50%\")\n",
    "            unwrapped_model = self.accelerator.unwrap_model(self.model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                checkpoint_dir,\n",
    "                save_function=self.accelerator.save\n",
    "            )\n",
    "            self.tokenizer.save_pretrained(checkpoint_dir)\n",
    "\n",
    "    def _save_predictions(self, test_df, predictions, probabilities):\n",
    "        \"\"\"Save predictions and probabilities\"\"\"\n",
    "        if self.accelerator.is_main_process:\n",
    "            # Save predictions\n",
    "            test_predictions_df = pd.DataFrame({\n",
    "                'tweet_id': test_df['tweet_id'],\n",
    "                'predicted_emotion': predictions,\n",
    "                'confidence': [max(probs) for probs in probabilities]\n",
    "            })\n",
    "            predictions_path = os.path.join(self.config.OUTPUT_DIR,\n",
    "                                          'test_predictions.csv')\n",
    "            test_predictions_df.to_csv(predictions_path, index=False)\n",
    "\n",
    "            # Save probabilities\n",
    "            probs_df = pd.DataFrame(\n",
    "                probabilities,\n",
    "                columns=[f'prob_class_{i}' for i in range(self.config.NUM_LABELS)]\n",
    "            )\n",
    "            probs_df['tweet_id'] = test_df['tweet_id']\n",
    "            probs_path = os.path.join(self.config.OUTPUT_DIR,\n",
    "                                    'test_probabilities.csv')\n",
    "            probs_df.to_csv(probs_path, index=False)\n",
    "\n",
    "            self.logger.info(f\"Predictions saved to {predictions_path}\")\n",
    "            self.logger.info(f\"Probabilities saved to {probs_path}\")\n",
    "\n",
    "            return test_predictions_df\n",
    "\n",
    "    def prepare_datasets(self, train_df):\n",
    "        \"\"\"Prepare and tokenize datasets, splitting training data into train and validation\"\"\"\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # Split training data into train and validation\n",
    "        train_df, val_df = train_test_split(\n",
    "            train_df,\n",
    "            test_size=0.2,  # 20% for validation\n",
    "            random_state=self.config.SEED\n",
    "        )\n",
    "\n",
    "        # Prepare datasets\n",
    "        train_dataset, val_dataset = ModelUtils.prepare_data_for_model(\n",
    "            train_df, val_df, self.tokenizer, self.config.MAX_LENGTH\n",
    "        )\n",
    "\n",
    "        # Create dataloaders\n",
    "        data_collator = DataCollatorWithPadding(self.tokenizer)\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            shuffle=True,\n",
    "            collate_fn=data_collator,\n",
    "            batch_size=self.config.BATCH_SIZE\n",
    "        )\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            collate_fn=data_collator,\n",
    "            batch_size=self.config.BATCH_SIZE\n",
    "        )\n",
    "\n",
    "        return train_dataloader, val_dataloader\n",
    "\n",
    "    def train(self, train_dataloader, eval_dataloader):\n",
    "        \"\"\"Train the emotion classification model\"\"\"\n",
    "        # Setup optimizer and scheduler\n",
    "        num_training_steps = self.config.NUM_EPOCHS * len(train_dataloader)\n",
    "        optimizer, lr_scheduler = self._setup_optimizer_and_scheduler(num_training_steps)\n",
    "\n",
    "        # Prepare everything with accelerator\n",
    "        self.model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = \\\n",
    "            self.accelerator.prepare(\n",
    "                self.model, optimizer, train_dataloader, eval_dataloader, lr_scheduler\n",
    "            )\n",
    "\n",
    "        # Initialize metrics tracking\n",
    "        training_losses = []\n",
    "        mean_f1_scores = []\n",
    "        progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.config.NUM_EPOCHS):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "\n",
    "            # Training\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                outputs = self.model(**batch)\n",
    "                loss = outputs.loss\n",
    "                self.accelerator.backward(loss)\n",
    "\n",
    "                epoch_loss += loss.detach().float()\n",
    "                training_losses.append(loss.detach().float().item())\n",
    "\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                progress_bar.update(1)\n",
    "\n",
    "            # Save checkpoint\n",
    "            self._save_checkpoint(epoch)\n",
    "\n",
    "            # Evaluation\n",
    "            self.model.eval()\n",
    "            eval_predictions = []\n",
    "            eval_labels = []\n",
    "\n",
    "            for batch in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(**batch)\n",
    "                predictions = outputs.logits.argmax(dim=-1)\n",
    "                predictions, references = self.accelerator.gather(\n",
    "                    (predictions, batch[\"labels\"])\n",
    "                )\n",
    "                eval_predictions.extend(predictions.cpu().numpy())\n",
    "                eval_labels.extend(references.cpu().numpy())\n",
    "\n",
    "            # Calculate metrics\n",
    "            metrics = ModelUtils.calculate_metrics(eval_predictions, eval_labels)\n",
    "            mean_f1_scores.append(metrics['mean_f1'])\n",
    "\n",
    "            # Log metrics\n",
    "            avg_loss = epoch_loss / len(train_dataloader)\n",
    "            print(f\"Epoch {epoch+1}:\")\n",
    "            print(f\"  Average loss = {avg_loss:.4f}\")\n",
    "            print(f\"  Mean F1 Score = {metrics['mean_f1']:.4f}\")\n",
    "            print(\"  F1 Score per class:\")\n",
    "            for i, f1 in enumerate(metrics['f1_per_class']):\n",
    "                print(f\"    Class {i}: {f1:.4f}\")\n",
    "\n",
    "        # Return results\n",
    "        metrics = {\n",
    "            'training_losses': training_losses,\n",
    "            'mean_f1_scores': mean_f1_scores,\n",
    "        }\n",
    "\n",
    "        return self.model, self.tokenizer, metrics\n",
    "    \n",
    "    def predict(self, test_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Prepare test data\n",
    "        test_text_df = pd.DataFrame({\n",
    "            'tweet_id': test_df['tweet_id'], \n",
    "            'text': test_df['text']\n",
    "        })\n",
    "        _, test_dataset = ModelUtils.prepare_data_for_model(\n",
    "            pd.DataFrame(),  # Empty DataFrame for train_df as it's not needed\n",
    "            test_text_df, \n",
    "            self.tokenizer\n",
    "        )\n",
    "\n",
    "        # Create test dataloader\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            collate_fn=DataCollatorWithPadding(self.tokenizer)\n",
    "        )\n",
    "\n",
    "        # Prepare for prediction\n",
    "        test_dataloader = self.accelerator.prepare(test_dataloader)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Make predictions\n",
    "        all_predictions = []\n",
    "        all_probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "                outputs = self.model(**batch)\n",
    "                predictions = outputs.logits.argmax(dim=-1)\n",
    "                probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "                \n",
    "                # Gather predictions and probabilities from all processes\n",
    "                predictions, probabilities = self.accelerator.gather((predictions, probabilities))\n",
    "                \n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "        # Convert numerical predictions back to emotion labels\n",
    "        inverse_emotion_mapping = {v: k for k, v in self.config.EMOTION_MAPPING.items()}\n",
    "        emotion_predictions = [inverse_emotion_mapping[pred] for pred in all_predictions]\n",
    "        \n",
    "        # Create predictions DataFrame\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'tweet_id': test_df['tweet_id'],\n",
    "            'predicted_emotion': emotion_predictions,\n",
    "            'confidence': [max(probs) for probs in all_probabilities]\n",
    "        })\n",
    "\n",
    "        # Add probability columns for each emotion\n",
    "        for emotion, idx in self.config.EMOTION_MAPPING.items():\n",
    "            predictions_df[f'prob_{emotion}'] = [probs[idx] for probs in all_probabilities]\n",
    "\n",
    "        return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "\n",
    "def main():\n",
    "    # Initialize configuration and accelerator\n",
    "    config = Config()\n",
    "    accelerator = Accelerator()\n",
    "    set_seed(config.SEED)\n",
    "    logger = get_logger(__name__)\n",
    "    os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Initialize data processor\n",
    "    data_processor = DataProcessor()\n",
    "\n",
    "    # Read raw data\n",
    "    tweets = data_processor.read_json_file('/content/drive/MyDrive/dm-2024/tweets_DM.json')\n",
    "    emotions = data_processor.read_csv_file('/content/drive/MyDrive/dm-2024/emotion.csv')\n",
    "    identification = data_processor.read_csv_file('/content/drive/MyDrive/dm-2024/data_identification.csv')\n",
    "\n",
    "    # Process data\n",
    "    tweets_df = pd.DataFrame(tweets)\n",
    "    merged_df = pd.merge(\n",
    "        tweets_df,\n",
    "        identification,\n",
    "        left_on='tweet_id',\n",
    "        right_on='tweet_id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Split data\n",
    "    train_df = merged_df[merged_df['identification'] == 'train']\n",
    "    test_df = merged_df[merged_df['identification'] == 'test']\n",
    "\n",
    "    # Merge with emotions for training data\n",
    "    train_df = pd.merge(\n",
    "        train_df,\n",
    "        emotions,\n",
    "        left_on='tweet_id',\n",
    "        right_on='tweet_id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Prepare final datasets\n",
    "    final_train = data_processor.prepare_dataset(train_df, is_training=True)\n",
    "    final_test = data_processor.prepare_dataset(test_df, is_training=False)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = EmotionClassificationTrainer(config, accelerator)\n",
    "\n",
    "    # Train model\n",
    "    train_dataloader, eval_dataloader = trainer.prepare_datasets(final_train)\n",
    "    trainer.train(train_dataloader, eval_dataloader)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_df = trainer.predict(final_test)\n",
    "    predictions_df.to_csv(os.path.join(config.OUTPUT_DIR, 'predictions.csv'), index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
